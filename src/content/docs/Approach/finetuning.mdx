---
title: Fine-Tuning Techniques
tableOfContents: false
template: doc
sidebar:
  order: 7
---

To achieve this dual functionality, we will employ advanced fine-tuning techniques. One approach is to use Low-Rank Adaptation (LoRA), which allows us to create two different versions of the same LLM: one optimized for keyword and parameter extraction and the other for user interaction. LoRA is particularly useful for fine-tuning large models with minimal computational resources, enabling us to efficiently adapt the LLM for our specific needs without extensive retraining.

By integrating these fine-tuned LLMs into our system, we aim to provide a seamless, intuitive search experience that leverages natural language while ensuring precise and efficient data extraction. This dual approach will not only enhance the accuracy of our search results but also improve overall user satisfaction.
